{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":27923,"databundleVersionId":3495119,"sourceType":"competition"},{"sourceId":3850683,"sourceType":"datasetVersion","datasetId":2290791},{"sourceId":3895325,"sourceType":"datasetVersion","datasetId":2256696}],"dockerImageVersionId":30204,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport nibabel as nib\nfrom tqdm import tqdm\nimport glob\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2024-05-15T21:39:25.345922Z","iopub.execute_input":"2024-05-15T21:39:25.347160Z","iopub.status.idle":"2024-05-15T21:39:25.579311Z","shell.execute_reply.started":"2024-05-15T21:39:25.347031Z","shell.execute_reply":"2024-05-15T21:39:25.578243Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#### infer https://www.kaggle.com/code/walterok/batch-inference-making-masks-using-nnunet/notebook\ndef make_if_dont_exist(folder_path,overwrite=False):\n    \"\"\"\n    creates a folder if it does not exists\n    input: \n    folder_path : relative path of the folder which needs to be created\n    over_write :(default: False) if True overwrite the existing folder \n    \"\"\"\n    if os.path.exists(folder_path):\n        \n        if not overwrite:\n            print(f'{folder_path} exists.')\n        else:\n            print(f\"{folder_path} overwritten\")\n            shutil.rmtree(folder_path)\n            os.makedirs(folder_path)\n\n    else:\n        os.makedirs(folder_path)\n        print(f\"{folder_path} created!\")","metadata":{"execution":{"iopub.status.busy":"2024-05-15T21:39:25.581246Z","iopub.execute_input":"2024-05-15T21:39:25.581642Z","iopub.status.idle":"2024-05-15T21:39:25.589128Z","shell.execute_reply.started":"2024-05-15T21:39:25.581604Z","shell.execute_reply":"2024-05-15T21:39:25.588109Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"make_if_dont_exist('/kaggle/working/nnUNet')\nmake_if_dont_exist('/kaggle/working/nnUNet_dep_libs/')","metadata":{"execution":{"iopub.status.busy":"2024-05-15T21:39:25.590285Z","iopub.execute_input":"2024-05-15T21:39:25.590596Z","iopub.status.idle":"2024-05-15T21:39:25.601205Z","shell.execute_reply.started":"2024-05-15T21:39:25.590567Z","shell.execute_reply":"2024-05-15T21:39:25.600190Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/working/nnUNet created!\n/kaggle/working/nnUNet_dep_libs/ created!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Install nnUNet libs**","metadata":{}},{"cell_type":"code","source":"### install MedPy-0.4.0\n!cp -rf /kaggle/input/nnunet-packages/packages/MedPy-0.4.0/MedPy-0.4.0  /kaggle/working/nnUNet_dep_libs/\n!cp -rf /kaggle/input/nnunet-packages/packages/batchgenerators-0.23 /kaggle/working/nnUNet_dep_libs/\n!cp -rf /kaggle/input/nnunet-packages/packages/dicom2nifti-2.3.3 /kaggle/working/nnUNet_dep_libs/\nrespository_dir = '/kaggle/working/nnUNet_dep_libs/'\nos.chdir(respository_dir)\n!ls","metadata":{"execution":{"iopub.status.busy":"2024-05-15T21:39:25.603403Z","iopub.execute_input":"2024-05-15T21:39:25.603687Z","iopub.status.idle":"2024-05-15T21:39:29.930343Z","shell.execute_reply.started":"2024-05-15T21:39:25.603661Z","shell.execute_reply":"2024-05-15T21:39:29.929039Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"MedPy-0.4.0  batchgenerators-0.23  dicom2nifti-2.3.3\n","output_type":"stream"}]},{"cell_type":"code","source":"### install MedPy\nmedpy_dir = f'/kaggle/working/nnUNet_dep_libs/MedPy-0.4.0/'\nos.chdir(medpy_dir)\n!ls\n!pip install -e .","metadata":{"execution":{"iopub.status.busy":"2024-05-15T21:39:29.931731Z","iopub.execute_input":"2024-05-15T21:39:29.932053Z","iopub.status.idle":"2024-05-15T21:40:14.645117Z","shell.execute_reply.started":"2024-05-15T21:39:29.932025Z","shell.execute_reply":"2024-05-15T21:40:14.643864Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"CHANGES.txt  MedPy.egg-info  README_PYPI.md  medpy\t\t   setup.py\nLICENSE.txt  PKG-INFO\t     bin\t     requirements-dev.txt\nMANIFEST.in  README.md\t     lib\t     setup.cfg\nObtaining file:///kaggle/working/nnUNet_dep_libs/MedPy-0.4.0\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from MedPy==0.4.0) (1.7.3)\nRequirement already satisfied: numpy>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from MedPy==0.4.0) (1.21.6)\nRequirement already satisfied: SimpleITK>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from MedPy==0.4.0) (2.1.1.2)\nInstalling collected packages: MedPy\n  Running setup.py develop for MedPy\nSuccessfully installed MedPy-0.4.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"### install batchgenerators\nbatchgenerators_dir = f'/kaggle/working/nnUNet_dep_libs/batchgenerators-0.23/'\nos.chdir(batchgenerators_dir)\n!ls\n!pip install -e .","metadata":{"execution":{"iopub.status.busy":"2024-05-15T21:40:14.647059Z","iopub.execute_input":"2024-05-15T21:40:14.647456Z","iopub.status.idle":"2024-05-15T21:40:49.786767Z","shell.execute_reply.started":"2024-05-15T21:40:14.647419Z","shell.execute_reply":"2024-05-15T21:40:49.785688Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"PKG-INFO  batchgenerators  batchgenerators.egg-info  setup.cfg\tsetup.py\nObtaining file:///kaggle/working/nnUNet_dep_libs/batchgenerators-0.23\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.7/site-packages (from batchgenerators==0.23) (9.1.1)\nRequirement already satisfied: numpy>=1.10.2 in /opt/conda/lib/python3.7/site-packages (from batchgenerators==0.23) (1.21.6)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from batchgenerators==0.23) (1.7.3)\nRequirement already satisfied: scikit-image in /opt/conda/lib/python3.7/site-packages (from batchgenerators==0.23) (0.18.3)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from batchgenerators==0.23) (1.0.2)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from batchgenerators==0.23) (0.18.2)\nRequirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->batchgenerators==0.23) (2.19.2)\nRequirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->batchgenerators==0.23) (2.5)\nRequirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->batchgenerators==0.23) (3.5.2)\nRequirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->batchgenerators==0.23) (1.3.0)\nRequirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.7/site-packages (from scikit-image->batchgenerators==0.23) (2021.11.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->batchgenerators==0.23) (3.1.0)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->batchgenerators==0.23) (1.1.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->batchgenerators==0.23) (21.3)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->batchgenerators==0.23) (4.33.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->batchgenerators==0.23) (1.4.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->batchgenerators==0.23) (2.8.2)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->batchgenerators==0.23) (3.0.9)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->batchgenerators==0.23) (0.11.0)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image->batchgenerators==0.23) (5.1.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->batchgenerators==0.23) (4.1.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib!=3.0.0,>=2.0.0->scikit-image->batchgenerators==0.23) (1.16.0)\nInstalling collected packages: batchgenerators\n  Running setup.py develop for batchgenerators\nSuccessfully installed batchgenerators-0.23\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"### install dicom2nifti\ndicom2nifti_dir = f'/kaggle/working/nnUNet_dep_libs/dicom2nifti-2.3.3/dicom2nifti-2.3.3'\nos.chdir(dicom2nifti_dir)\n!ls\n!pip install -e .","metadata":{"execution":{"iopub.status.busy":"2024-05-15T21:40:49.788473Z","iopub.execute_input":"2024-05-15T21:40:49.789403Z","iopub.status.idle":"2024-05-15T21:41:24.570931Z","shell.execute_reply.started":"2024-05-15T21:40:49.789358Z","shell.execute_reply":"2024-05-15T21:41:24.569775Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"LICENSE   README.rst   dicom2nifti.egg-info  setup.cfg\nPKG-INFO  dicom2nifti  scripts\t\t     setup.py\nObtaining file:///kaggle/working/nnUNet_dep_libs/dicom2nifti-2.3.3/dicom2nifti-2.3.3\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: nibabel in /opt/conda/lib/python3.7/site-packages (from dicom2nifti==2.3.3) (3.2.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from dicom2nifti==2.3.3) (1.21.6)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from dicom2nifti==2.3.3) (1.7.3)\nRequirement already satisfied: pydicom>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from dicom2nifti==2.3.3) (2.3.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from nibabel->dicom2nifti==2.3.3) (59.8.0)\nRequirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from nibabel->dicom2nifti==2.3.3) (21.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=14.3->nibabel->dicom2nifti==2.3.3) (3.0.9)\nInstalling collected packages: dicom2nifti\n  Running setup.py develop for dicom2nifti\nSuccessfully installed dicom2nifti-2.3.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"### install nnUNet\n!cp -rf /kaggle/input/uwmgit-nnunet/nnUNet-master /kaggle/working/nnUNet\nnnunet_dir = '/kaggle/working/nnUNet/nnUNet-master'\nos.chdir(nnunet_dir)\n!ls\n!pip install -e .","metadata":{"execution":{"iopub.status.busy":"2024-05-15T21:41:24.572797Z","iopub.execute_input":"2024-05-15T21:41:24.573583Z","iopub.status.idle":"2024-05-15T21:42:01.682160Z","shell.execute_reply.started":"2024-05-15T21:41:24.573539Z","shell.execute_reply":"2024-05-15T21:42:01.680895Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"HI_Logo.png  documentation  readme.md  setup.py\nLICENSE      nnunet\t    setup.cfg  tests\nObtaining file:///kaggle/working/nnUNet/nnUNet-master\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch>1.10.0 in /opt/conda/lib/python3.7/site-packages (from nnunet==1.7.0) (1.11.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from nnunet==1.7.0) (4.64.0)\nRequirement already satisfied: dicom2nifti in /kaggle/working/nnUNet_dep_libs/dicom2nifti-2.3.3/dicom2nifti-2.3.3 (from nnunet==1.7.0) (2.3.3)\nRequirement already satisfied: scikit-image>=0.14 in /opt/conda/lib/python3.7/site-packages (from nnunet==1.7.0) (0.18.3)\nRequirement already satisfied: medpy in /kaggle/working/nnUNet_dep_libs/MedPy-0.4.0 (from nnunet==1.7.0) (0.4.0)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from nnunet==1.7.0) (1.7.3)\nRequirement already satisfied: batchgenerators>=0.23 in /kaggle/working/nnUNet_dep_libs/batchgenerators-0.23 (from nnunet==1.7.0) (0.23)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from nnunet==1.7.0) (1.21.6)\nRequirement already satisfied: sklearn in /opt/conda/lib/python3.7/site-packages (from nnunet==1.7.0) (0.0)\nRequirement already satisfied: SimpleITK in /opt/conda/lib/python3.7/site-packages (from nnunet==1.7.0) (2.1.1.2)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from nnunet==1.7.0) (1.3.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from nnunet==1.7.0) (2.27.1)\nRequirement already satisfied: nibabel in /opt/conda/lib/python3.7/site-packages (from nnunet==1.7.0) (3.2.2)\nRequirement already satisfied: tifffile in /opt/conda/lib/python3.7/site-packages (from nnunet==1.7.0) (2021.11.2)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from nnunet==1.7.0) (3.5.2)\nRequirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.7/site-packages (from batchgenerators>=0.23->nnunet==1.7.0) (9.1.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from batchgenerators>=0.23->nnunet==1.7.0) (1.0.2)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from batchgenerators>=0.23->nnunet==1.7.0) (0.18.2)\nRequirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.14->nnunet==1.7.0) (2.19.2)\nRequirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.14->nnunet==1.7.0) (2.5)\nRequirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image>=0.14->nnunet==1.7.0) (1.3.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->nnunet==1.7.0) (0.11.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->nnunet==1.7.0) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->nnunet==1.7.0) (2.8.2)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->nnunet==1.7.0) (1.4.2)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->nnunet==1.7.0) (4.33.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->nnunet==1.7.0) (21.3)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>1.10.0->nnunet==1.7.0) (4.1.1)\nRequirement already satisfied: pydicom>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from dicom2nifti->nnunet==1.7.0) (2.3.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from nibabel->nnunet==1.7.0) (59.8.0)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->nnunet==1.7.0) (2022.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->nnunet==1.7.0) (2022.6.15)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->nnunet==1.7.0) (1.26.9)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->nnunet==1.7.0) (2.0.12)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->nnunet==1.7.0) (3.3)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image>=0.14->nnunet==1.7.0) (5.1.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib->nnunet==1.7.0) (1.16.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->batchgenerators>=0.23->nnunet==1.7.0) (3.1.0)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->batchgenerators>=0.23->nnunet==1.7.0) (1.1.0)\nInstalling collected packages: nnunet\n  Running setup.py develop for nnunet\nSuccessfully installed nnunet-1.7.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Create dirs**","metadata":{}},{"cell_type":"code","source":"base_nnunet_dir = \"/kaggle/working/input/\"\nraw_data_base_dir = \"/kaggle/working/input/nnUNet_raw_data_base\"\npreprocessed_dir = \"/kaggle/working/input/nnUNet_preprocessed\"\ntrained_models_dir = \"/kaggle/working/input/nnUNet_trained_models\"\n\ntask_name = 'Task522_UWMGITImageSegmentation' #change here for different task name\ntask_folder_name = os.path.join(raw_data_base_dir, 'nnUNet_raw_data', task_name)\nimagestr = os.path.join(task_folder_name,'imagesTr')\nimagests = os.path.join(task_folder_name,'imagesTs')\nlabelstr = os.path.join(task_folder_name,'labelsTr')\noutput_dir = \"/kaggle/working/output/segmented\"\n\nmake_if_dont_exist(base_nnunet_dir, overwrite = False)\nmake_if_dont_exist(raw_data_base_dir, overwrite = False)\nmake_if_dont_exist(preprocessed_dir, overwrite = False)\nmake_if_dont_exist(trained_models_dir, overwrite = False)\nmake_if_dont_exist(imagestr, overwrite = False)\nmake_if_dont_exist(imagests, overwrite = False)\nmake_if_dont_exist(labelstr, overwrite = False)\nmake_if_dont_exist(output_dir, overwrite = False)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T21:42:01.683767Z","iopub.execute_input":"2024-05-15T21:42:01.684088Z","iopub.status.idle":"2024-05-15T21:42:01.695969Z","shell.execute_reply.started":"2024-05-15T21:42:01.684057Z","shell.execute_reply":"2024-05-15T21:42:01.694925Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"/kaggle/working/input/ created!\n/kaggle/working/input/nnUNet_raw_data_base created!\n/kaggle/working/input/nnUNet_preprocessed created!\n/kaggle/working/input/nnUNet_trained_models created!\n/kaggle/working/input/nnUNet_raw_data_base/nnUNet_raw_data/Task522_UWMGITImageSegmentation/imagesTr created!\n/kaggle/working/input/nnUNet_raw_data_base/nnUNet_raw_data/Task522_UWMGITImageSegmentation/imagesTs created!\n/kaggle/working/input/nnUNet_raw_data_base/nnUNet_raw_data/Task522_UWMGITImageSegmentation/labelsTr created!\n/kaggle/working/output/segmented created!\n","output_type":"stream"}]},{"cell_type":"code","source":"train_folder = os.path.join(base_nnunet_dir, \"train_images/\")\ntest_folder = os.path.join(base_nnunet_dir, \"test_images/\")\nlabel_folder = os.path.join(base_nnunet_dir, \"masks/\")\n\nmake_if_dont_exist(train_folder, overwrite = False)\nmake_if_dont_exist(test_folder, overwrite = False)\nmake_if_dont_exist(label_folder, overwrite = False)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T21:42:01.700083Z","iopub.execute_input":"2024-05-15T21:42:01.700351Z","iopub.status.idle":"2024-05-15T21:42:01.707891Z","shell.execute_reply.started":"2024-05-15T21:42:01.700326Z","shell.execute_reply":"2024-05-15T21:42:01.706909Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"/kaggle/working/input/train_images/ created!\n/kaggle/working/input/test_images/ created!\n/kaggle/working/input/masks/ created!\n","output_type":"stream"}]},{"cell_type":"code","source":"os.chdir('/kaggle/working/')\n!ls","metadata":{"execution":{"iopub.status.busy":"2024-05-15T21:42:01.709127Z","iopub.execute_input":"2024-05-15T21:42:01.709497Z","iopub.status.idle":"2024-05-15T21:42:02.676035Z","shell.execute_reply.started":"2024-05-15T21:42:01.709458Z","shell.execute_reply":"2024-05-15T21:42:02.674674Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"input  nnUNet  nnUNet_dep_libs\toutput\n","output_type":"stream"}]},{"cell_type":"code","source":"### copy pretrained models\n# pretrained_model_dir_new = \"/kaggle/working/input/nnunet-pretrained-brain-tumor-segmentation-network\"\n# !cp -rf ../input/nnunet-pretrained-brain-tumor-segmentation-network/* input/nnunet-pretrained-brain-tumor-segmentation-network/nnUNet","metadata":{"execution":{"iopub.status.busy":"2024-05-15T21:42:02.678116Z","iopub.execute_input":"2024-05-15T21:42:02.678716Z","iopub.status.idle":"2024-05-15T21:42:02.686169Z","shell.execute_reply.started":"2024-05-15T21:42:02.678666Z","shell.execute_reply":"2024-05-15T21:42:02.685038Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# **Helpers**","metadata":{}},{"cell_type":"code","source":"#### inference by https://github.com/Borda/kaggle_image-segm/blob/main/kaggle_imsegm/mask.py\nfrom typing import Dict\ndef rle_decode(mask_rle: str, img: np.ndarray = None, img_shape: tuple = None, label: int = 1) -> np.ndarray:\n    \"\"\"Create a single label mask for Run-length encoding.\n    >>> mask = rle_decode(\"3 2 11 5 23 3 35 1\", img_shape=(8, 10))\n    >>> mask = rle_decode(\"55 3 66 2 77 1\", img=mask, label=2)\n    >>> mask = rle_decode(\"26 3 36 2\", img=mask, label=3)\n    >>> mask\n    array([[0, 0, 0, 1, 1, 0, 0, 0, 0, 0],\n           [0, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n           [0, 0, 0, 1, 1, 1, 3, 3, 3, 0],\n           [0, 0, 0, 0, 0, 1, 3, 3, 0, 0],\n           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n           [0, 0, 0, 0, 0, 2, 2, 2, 0, 0],\n           [0, 0, 0, 0, 0, 0, 2, 2, 0, 0],\n           [0, 0, 0, 0, 0, 0, 0, 2, 0, 0]], dtype=uint16)\n    >>> from pprint import pprint\n    >>> pprint(rle_encode(mask))\n    {1: '3 2 11 5 23 3 35 1', 2: '55 3 66 2 77 1', 3: '26 3 36 2'}\n    \"\"\"\n    seq = mask_rle.split()\n    starts = np.array(list(map(int, seq[0::2])))\n    lengths = np.array(list(map(int, seq[1::2])))\n    assert len(starts) == len(lengths)\n    ends = starts + lengths\n\n    if img is None:\n        img = np.zeros((np.product(img_shape),), dtype=np.uint16)\n    else:\n        img_shape = img.shape\n        img = img.flatten()\n    for begin, end in zip(starts, ends):\n        img[begin:end] = label\n    return img.reshape(img_shape)\n\n\ndef rle_encode(mask: np.ndarray, label_bg: int = 0) -> Dict[int, str]:\n    \"\"\"Encode mask to Run-length encoding.\n    Inspiration took from: https://gist.github.com/nvictus/66627b580c13068589957d6ab0919e66\n    >>> from pprint import pprint\n    >>> mask = np.array([[0, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n    ...                  [0, 0, 0, 1, 1, 1, 2, 2, 2, 0],\n    ...                  [0, 0, 0, 0, 0, 1, 3, 3, 0, 0],])\n    >>> pprint(rle_encode(mask))\n    {1: '1 5 13 3 25 1', 2: '16 3', 3: '26 2'}\n    \"\"\"\n    vec = mask.flatten()\n    nb = len(vec)\n    where = np.flatnonzero\n    starts = np.r_[0, where(~np.isclose(vec[1:], vec[:-1], equal_nan=True)) + 1]\n    lengths = np.diff(np.r_[starts, nb])\n    values = vec[starts]\n    assert len(starts) == len(lengths) == len(values)\n    rle = {}\n    for start, length, val in zip(starts, lengths, values):\n        if val == label_bg:\n            continue\n        rle[val] = rle.get(val, []) + [str(start), length]\n    # post-processing\n    rle = {lb: \" \".join(map(str, id_lens)) for lb, id_lens in rle.items()}\n    return rle\n\ndef load_image_volume(img_dir, quant=0.01):\n    imgs = sorted(glob.glob(os.path.join(img_dir, f\"*.png\")))\n    imgs = [np.array(Image.open(p)).tolist() for p in imgs]\n    # print([np.max(im) for im in imgs])\n    vol = np.array(imgs)\n    if quant:\n        q_low, q_high = np.percentile(vol, [quant * 100, (1 - quant) * 100])\n        vol = np.clip(vol, q_low, q_high)\n    v_min, v_max = np.min(vol), np.max(vol)\n    vol = (vol - v_min) / (v_max - v_min)\n    vol = (vol * 255).astype(np.uint8)\n    return vol\n\ndef create_organs_segm(df_vol, vol_shape):\n    df_vol = df_vol.replace(np.nan, '')\n    segm = np.zeros(vol_shape, dtype=np.uint8)\n    lbs = sorted(df_vol[\"class\"].unique())\n#     print(f'lbs is {lbs}')\n    for idx_, dfg in df_vol.groupby(\"Slice\"):\n        idx = int(idx_) - 1\n        mask = segm[idx, :, :]\n        for _, (lb, rle) in dfg[[\"class\", \"segmentation\"]].iterrows():\n            lb = lbs.index(lb) + 1\n            if not rle:\n                continue\n            mask = rle_decode(rle, img=mask, label=lb)\n        segm[idx, :, :] = mask\n        # plt.figure(); plt.imshow(mask)\n    return segm","metadata":{"execution":{"iopub.status.busy":"2024-05-15T21:42:02.687876Z","iopub.execute_input":"2024-05-15T21:42:02.688764Z","iopub.status.idle":"2024-05-15T21:42:02.721873Z","shell.execute_reply.started":"2024-05-15T21:42:02.688725Z","shell.execute_reply":"2024-05-15T21:42:02.720880Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# **Load data**","metadata":{}},{"cell_type":"code","source":"root_dir = \"/kaggle/input/uw-madison-gi-tract-image-segmentation\"\ntrain_dir = f\"{root_dir}/train\"\ntest_dir = f\"{root_dir}/test\"\ntrain_csv_path = f\"{root_dir}/train.csv\"\nsample_csv_path = f\"{root_dir}/sample_submission.csv\"","metadata":{"execution":{"iopub.status.busy":"2024-05-15T21:42:02.723054Z","iopub.execute_input":"2024-05-15T21:42:02.725543Z","iopub.status.idle":"2024-05-15T21:42:02.738266Z","shell.execute_reply.started":"2024-05-15T21:42:02.725513Z","shell.execute_reply":"2024-05-15T21:42:02.737293Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(train_csv_path)\ndf_train","metadata":{"execution":{"iopub.status.busy":"2024-05-15T21:42:02.739642Z","iopub.execute_input":"2024-05-15T21:42:02.739954Z","iopub.status.idle":"2024-05-15T21:42:03.300647Z","shell.execute_reply.started":"2024-05-15T21:42:02.739919Z","shell.execute_reply":"2024-05-15T21:42:03.299628Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"                              id        class segmentation\n0       case123_day20_slice_0001  large_bowel          NaN\n1       case123_day20_slice_0001  small_bowel          NaN\n2       case123_day20_slice_0001      stomach          NaN\n3       case123_day20_slice_0002  large_bowel          NaN\n4       case123_day20_slice_0002  small_bowel          NaN\n...                          ...          ...          ...\n115483    case30_day0_slice_0143  small_bowel          NaN\n115484    case30_day0_slice_0143      stomach          NaN\n115485    case30_day0_slice_0144  large_bowel          NaN\n115486    case30_day0_slice_0144  small_bowel          NaN\n115487    case30_day0_slice_0144      stomach          NaN\n\n[115488 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>class</th>\n      <th>segmentation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>case123_day20_slice_0001</td>\n      <td>large_bowel</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>case123_day20_slice_0001</td>\n      <td>small_bowel</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>case123_day20_slice_0001</td>\n      <td>stomach</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>case123_day20_slice_0002</td>\n      <td>large_bowel</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>case123_day20_slice_0002</td>\n      <td>small_bowel</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>115483</th>\n      <td>case30_day0_slice_0143</td>\n      <td>small_bowel</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>115484</th>\n      <td>case30_day0_slice_0143</td>\n      <td>stomach</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>115485</th>\n      <td>case30_day0_slice_0144</td>\n      <td>large_bowel</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>115486</th>\n      <td>case30_day0_slice_0144</td>\n      <td>small_bowel</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>115487</th>\n      <td>case30_day0_slice_0144</td>\n      <td>stomach</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>115488 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_test = pd.read_csv(sample_csv_path)\ndf_test","metadata":{"execution":{"iopub.status.busy":"2024-05-15T21:42:03.301903Z","iopub.execute_input":"2024-05-15T21:42:03.302233Z","iopub.status.idle":"2024-05-15T21:42:03.321011Z","shell.execute_reply.started":"2024-05-15T21:42:03.302204Z","shell.execute_reply":"2024-05-15T21:42:03.320026Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"Empty DataFrame\nColumns: [id, class, predicted]\nIndex: []","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>class</th>\n      <th>predicted</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# **Generate train data**","metadata":{}},{"cell_type":"code","source":"def extract_details(id_):\n    id_fields = id_.split(\"_\")\n    case = id_fields[0].replace(\"case\", \"\")\n    day = id_fields[1].replace(\"day\", \"\")\n    slice_id = id_fields[3]\n    img_dir = os.path.join(root_dir, \"train\",\n                           f\"case{case}\", f\"case{case}_day{day}\", \"scans\")\n    imgs = glob.glob(os.path.join(img_dir, f\"slice_{slice_id}_*.png\"))\n    assert len(imgs) == 1\n    img_path = imgs[0].replace(root_dir + \"/\", \"\")\n    img = os.path.basename(img_path)\n    # slice_0001_266_266_1.50_1.50.png\n    im_fields = img.split(\"_\")\n    return {\n        \"Case\": int(case),\n        \"Day\": int(day),\n        \"Slice\": slice_id,\n        \"image\": img,\n        \"image_path\": img_path, \n        \"height\": int(im_fields[3]),\n        \"width\": int(im_fields[2]),\n    }","metadata":{"execution":{"iopub.status.busy":"2024-05-15T21:42:03.322302Z","iopub.execute_input":"2024-05-15T21:42:03.322611Z","iopub.status.idle":"2024-05-15T21:42:03.332450Z","shell.execute_reply.started":"2024-05-15T21:42:03.322583Z","shell.execute_reply":"2024-05-15T21:42:03.331351Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"df_train[['Case','Day','Slice', 'image', 'image_path', 'height', 'width']] = \\\n    df_train['id'].apply(lambda x: pd.Series(extract_details(x)))\ndisplay(df_train.head())","metadata":{"execution":{"iopub.status.busy":"2024-05-15T21:42:03.333729Z","iopub.execute_input":"2024-05-15T21:42:03.334206Z","iopub.status.idle":"2024-05-15T21:44:26.219777Z","shell.execute_reply.started":"2024-05-15T21:42:03.334167Z","shell.execute_reply":"2024-05-15T21:44:26.218822Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"                         id        class segmentation  Case  Day Slice  \\\n0  case123_day20_slice_0001  large_bowel          NaN   123   20  0001   \n1  case123_day20_slice_0001  small_bowel          NaN   123   20  0001   \n2  case123_day20_slice_0001      stomach          NaN   123   20  0001   \n3  case123_day20_slice_0002  large_bowel          NaN   123   20  0002   \n4  case123_day20_slice_0002  small_bowel          NaN   123   20  0002   \n\n                              image  \\\n0  slice_0001_266_266_1.50_1.50.png   \n1  slice_0001_266_266_1.50_1.50.png   \n2  slice_0001_266_266_1.50_1.50.png   \n3  slice_0002_266_266_1.50_1.50.png   \n4  slice_0002_266_266_1.50_1.50.png   \n\n                                          image_path  height  width  \n0  train/case123/case123_day20/scans/slice_0001_2...     266    266  \n1  train/case123/case123_day20/scans/slice_0001_2...     266    266  \n2  train/case123/case123_day20/scans/slice_0001_2...     266    266  \n3  train/case123/case123_day20/scans/slice_0002_2...     266    266  \n4  train/case123/case123_day20/scans/slice_0002_2...     266    266  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>class</th>\n      <th>segmentation</th>\n      <th>Case</th>\n      <th>Day</th>\n      <th>Slice</th>\n      <th>image</th>\n      <th>image_path</th>\n      <th>height</th>\n      <th>width</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>case123_day20_slice_0001</td>\n      <td>large_bowel</td>\n      <td>NaN</td>\n      <td>123</td>\n      <td>20</td>\n      <td>0001</td>\n      <td>slice_0001_266_266_1.50_1.50.png</td>\n      <td>train/case123/case123_day20/scans/slice_0001_2...</td>\n      <td>266</td>\n      <td>266</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>case123_day20_slice_0001</td>\n      <td>small_bowel</td>\n      <td>NaN</td>\n      <td>123</td>\n      <td>20</td>\n      <td>0001</td>\n      <td>slice_0001_266_266_1.50_1.50.png</td>\n      <td>train/case123/case123_day20/scans/slice_0001_2...</td>\n      <td>266</td>\n      <td>266</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>case123_day20_slice_0001</td>\n      <td>stomach</td>\n      <td>NaN</td>\n      <td>123</td>\n      <td>20</td>\n      <td>0001</td>\n      <td>slice_0001_266_266_1.50_1.50.png</td>\n      <td>train/case123/case123_day20/scans/slice_0001_2...</td>\n      <td>266</td>\n      <td>266</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>case123_day20_slice_0002</td>\n      <td>large_bowel</td>\n      <td>NaN</td>\n      <td>123</td>\n      <td>20</td>\n      <td>0002</td>\n      <td>slice_0002_266_266_1.50_1.50.png</td>\n      <td>train/case123/case123_day20/scans/slice_0002_2...</td>\n      <td>266</td>\n      <td>266</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>case123_day20_slice_0002</td>\n      <td>small_bowel</td>\n      <td>NaN</td>\n      <td>123</td>\n      <td>20</td>\n      <td>0002</td>\n      <td>slice_0002_266_266_1.50_1.50.png</td>\n      <td>train/case123/case123_day20/scans/slice_0002_2...</td>\n      <td>266</td>\n      <td>266</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_scans_dir = []\nfor dirname, _, filenames in os.walk(f'{root_dir}/train'):\n    if dirname.endswith('scans'):\n        train_scans_dir.append(dirname)\n        \nprint(f'Found {len(train_scans_dir)} scans directories')\n\ndebug = True ###just select 10 samples for training, please set debug=False for using all train data\nfor index, s_dir in tqdm(enumerate(train_scans_dir),total=len(train_scans_dir)):\n    if debug and index == 10:\n        break\n    image_id = s_dir.split('/')[-2]\n    case_str, day_str= image_id.split('_')\n    case = int(case_str.split('case')[-1])\n    day = int(day_str.split('day')[-1])\n\n    IMAGE_FOLDER = os.path.join(root_dir, \"train\", f\"case{case}\", f\"case{case}_day{day}\", \"scans\")\n    vol = load_image_volume(img_dir=IMAGE_FOLDER)\n            \n    ### convert np to nibabel reference https://gist.github.com/tonyreina/64ac5703251b87118cf5d2886169fd5a\n    img = nib.Nifti1Image(vol, np.eye(4))  # Save axis for data (just identity)\n    img.header.get_xyzt_units()\n    img.to_filename(f'{train_folder}/{image_id}.nii.gz')  # Save as NiBabel file\n    \n    df_ = df_train[(df_train[\"Case\"] == case) & (df_train[\"Day\"] == day)]\n    segm = create_organs_segm(df_vol=df_, vol_shape=vol.shape)\n    \n    mask = nib.Nifti1Image(segm, np.eye(4))  # Save axis for data (just identity)\n    mask.header.get_xyzt_units()\n    mask.to_filename(f'{label_folder}/{image_id}.nii.gz')  # Save as NiBabel file","metadata":{"execution":{"iopub.status.busy":"2024-05-15T21:44:26.221085Z","iopub.execute_input":"2024-05-15T21:44:26.221404Z","iopub.status.idle":"2024-05-15T21:45:05.859038Z","shell.execute_reply.started":"2024-05-15T21:44:26.221375Z","shell.execute_reply":"2024-05-15T21:45:05.858048Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Found 274 scans directories\n","output_type":"stream"},{"name":"stderr","text":"  4%|▎         | 10/274 [00:38<17:04,  3.88s/it]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Generate test data**","metadata":{}},{"cell_type":"code","source":"#### https://www.kaggle.com/code/outwrest/create-gifs-of-medical-3d-images\nscans_dir = []\n\nif df_test.shape[0] == 0: ### select data from train\n    for dirname, _, filenames in os.walk(f'{root_dir}/train'):\n        if dirname.endswith('scans'):\n            scans_dir.append(dirname)\nelse:\n    for dirname, _, filenames in os.walk(f'{root_dir}/test'):\n        if dirname.endswith('scans'):\n            scans_dir.append(dirname)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T21:45:05.860579Z","iopub.execute_input":"2024-05-15T21:45:05.861011Z","iopub.status.idle":"2024-05-15T21:45:06.265067Z","shell.execute_reply.started":"2024-05-15T21:45:05.860953Z","shell.execute_reply":"2024-05-15T21:45:06.263857Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"if df_test.shape[0] == 0:\n    for index, s_dir in tqdm(enumerate(scans_dir),total=len(scans_dir)):\n        image_id = s_dir.split('/')[-2]\n        case_str, day_str= image_id.split('_')\n        case = int(case_str.split('case')[-1])\n        day = int(day_str.split('day')[-1])\n        if index < 5:\n            IMAGE_FOLDER = os.path.join(root_dir, \"train\", f\"case{case}\", f\"case{case}_day{day}\", \"scans\")\n            vol = load_image_volume(img_dir=IMAGE_FOLDER)\n            \n            ### convert np to nibabel reference https://gist.github.com/tonyreina/64ac5703251b87118cf5d2886169fd5a\n            img = nib.Nifti1Image(vol, np.eye(4))  # Save axis for data (just identity)\n            img.header.get_xyzt_units()\n            img.to_filename(f'{test_folder}/{image_id}.nii.gz')  # Save as NiBabel file\n            \nelse:\n    for index, s_dir in tqdm(enumerate(scans_dir),total=len(scans_dir)):\n        image_id = s_dir.split('/')[-2]\n        case_str, day_str= image_id.split('_')\n        case = int(case_str.split('case')[-1])\n        day = int(day_str.split('day')[-1])\n        \n        IMAGE_FOLDER = os.path.join(root_dir, \"test\", f\"case{case}\", f\"case{case}_day{day}\", \"scans\")\n        vol = load_image_volume(img_dir=IMAGE_FOLDER)\n        \n        ### convert np to nibabel reference https://gist.github.com/tonyreina/64ac5703251b87118cf5d2886169fd5a\n        img = nib.Nifti1Image(vol, np.eye(4))  # Save axis for data (just identity)\n        img.header.get_xyzt_units()\n        img.to_filename(f'{test_folder}/{image_id}.nii.gz')  # Save as NiBabel file","metadata":{"execution":{"iopub.status.busy":"2024-05-15T21:45:06.266483Z","iopub.execute_input":"2024-05-15T21:45:06.266811Z","iopub.status.idle":"2024-05-15T21:45:20.437161Z","shell.execute_reply.started":"2024-05-15T21:45:06.266782Z","shell.execute_reply":"2024-05-15T21:45:20.436015Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"100%|██████████| 274/274 [00:14<00:00, 19.36it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/working/nnUNet_dep_libs/batchgenerators-0.23')\nsys.path.append('/kaggle/working/nnUNet/nnUNet-master/')\nfrom collections import OrderedDict\nfrom nnunet.paths import nnUNet_raw_data\nfrom batchgenerators.utilities.file_and_folder_operations import *\nfrom nnunet.dataset_conversion.utils import generate_dataset_json\nimport shutil","metadata":{"execution":{"iopub.status.busy":"2024-05-15T21:45:20.438477Z","iopub.execute_input":"2024-05-15T21:45:20.438792Z","iopub.status.idle":"2024-05-15T21:45:20.453685Z","shell.execute_reply.started":"2024-05-15T21:45:20.438762Z","shell.execute_reply":"2024-05-15T21:45:20.452577Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"\n\nPlease cite the following paper when using nnUNet:\n\nIsensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n\n\nIf you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n\nnnUNet_raw_data_base is not defined and nnU-Net can only be used on data for which preprocessed files are already present on your system. nnU-Net cannot be used for experiment planning and preprocessing like this. If this is not intended, please read documentation/setting_up_paths.md for information on how to set this up properly.\nnnUNet_preprocessed is not defined and nnU-Net can not be used for preprocessing or training. If this is not intended, please read documentation/setting_up_paths.md for information on how to set this up.\nRESULTS_FOLDER is not defined and nnU-Net cannot be used for training or inference. If this is not intended behavior, please read documentation/setting_up_paths.md for information on how to set this up.\n","output_type":"stream"}]},{"cell_type":"code","source":"train_patient_names = []\ntest_patient_names = []\ntrain_patients = subfiles(train_folder, join=False, suffix = 'nii.gz')\ntest_patients = subfiles(test_folder, join=False, suffix = 'nii.gz')\n\nprint(train_patients[0])\nprint(len(train_patients))\nprint(test_patients[0])\nprint(len(test_patients))\n\nfor index,patient_name in tqdm(enumerate(train_patients),total=len(train_patients)):\n    pex_name = patient_name.split('.')[0]\n    image_file = join(train_folder,patient_name)\n    label_file = join(label_folder,patient_name)\n    \n    shutil.copy(image_file, join(imagestr, f'{pex_name}_0000.nii.gz'))\n    shutil.copy(label_file, join(labelstr, patient_name))\n    \nfor index,patient_name in tqdm(enumerate(test_patients),total=len(test_patients)):\n    pex_name = patient_name.split('.')[0]\n    image_file = join(test_folder,patient_name)\n    \n    shutil.copy(image_file, join(imagests, f'{pex_name}_0000.nii.gz'))","metadata":{"execution":{"iopub.status.busy":"2024-05-15T21:45:20.455048Z","iopub.execute_input":"2024-05-15T21:45:20.455454Z","iopub.status.idle":"2024-05-15T21:45:20.588360Z","shell.execute_reply.started":"2024-05-15T21:45:20.455415Z","shell.execute_reply":"2024-05-15T21:45:20.587354Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"case135_day0.nii.gz\n10\ncase36_day10.nii.gz\n5\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:00<00:00, 130.23it/s]\n100%|██████████| 5/5 [00:00<00:00, 130.75it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"generate_dataset_json(join(task_folder_name, 'dataset.json'),\n                          imagestr,\n                          imagests,\n                          ('CT',),\n                          {\n                              0: 'background',\n                              1: \"large_bowel\",\n                              2: \"small_bowel\",\n                              3: \"stomach\",\n                          },\n                          task_name,\n                          license='see challenge website',\n                          dataset_description='kaggle-uw-madison-gi-tract-image-segmentation',\n                          dataset_reference='https://www.kaggle.com/competitions/uw-madison-gi-tract-image-segmentation',\n                          dataset_release='0')","metadata":{"execution":{"iopub.status.busy":"2024-05-15T21:45:20.589826Z","iopub.execute_input":"2024-05-15T21:45:20.590513Z","iopub.status.idle":"2024-05-15T21:45:20.597584Z","shell.execute_reply.started":"2024-05-15T21:45:20.590471Z","shell.execute_reply":"2024-05-15T21:45:20.596633Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"os.chdir('/kaggle/working/nnUNet/nnUNet-master')\n!ls","metadata":{"execution":{"iopub.status.busy":"2024-05-15T21:45:20.598928Z","iopub.execute_input":"2024-05-15T21:45:20.599498Z","iopub.status.idle":"2024-05-15T21:45:21.575131Z","shell.execute_reply.started":"2024-05-15T21:45:20.599461Z","shell.execute_reply":"2024-05-15T21:45:21.574039Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"HI_Logo.png  documentation  nnunet.egg-info  setup.cfg\ttests\nLICENSE      nnunet\t    readme.md\t     setup.py\n","output_type":"stream"}]},{"cell_type":"code","source":"### set environment veriables\nos.environ['nnUNet_raw_data_base'] = raw_data_base_dir\nos.environ['nnUNet_preprocessed'] = preprocessed_dir\nos.environ['RESULTS_FOLDER'] = trained_models_dir","metadata":{"execution":{"iopub.status.busy":"2024-05-15T21:45:21.576805Z","iopub.execute_input":"2024-05-15T21:45:21.577151Z","iopub.status.idle":"2024-05-15T21:45:21.582634Z","shell.execute_reply.started":"2024-05-15T21:45:21.577120Z","shell.execute_reply":"2024-05-15T21:45:21.581667Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"# **Data preprocessing**","metadata":{}},{"cell_type":"code","source":"!nnUNet_plan_and_preprocess -t 522 --verify_dataset_integrity","metadata":{"execution":{"iopub.status.busy":"2024-05-15T21:45:21.583812Z","iopub.execute_input":"2024-05-15T21:45:21.584127Z","iopub.status.idle":"2024-05-15T21:46:10.257469Z","shell.execute_reply.started":"2024-05-15T21:45:21.584100Z","shell.execute_reply":"2024-05-15T21:46:10.256308Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"\n\nPlease cite the following paper when using nnUNet:\n\nIsensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n\n\nIf you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n\nVerifying training set\nchecking case case135_day0\nchecking case case135_day17\nchecking case case20_day22\nchecking case case22_day0\nchecking case case36_day0\nchecking case case36_day10\nchecking case case36_day14\nchecking case case36_day16\nchecking case case36_day6\nchecking case case36_day8\nVerifying label values\nExpected label values are [0, 1, 2, 3]\nLabels OK\nVerifying test set\nDataset OK\ncase135_day0\ncase135_day17\ncase20_day22\ncase22_day0\ncase36_day10\ncase36_day14\ncase36_day0\ncase36_day16\nbefore crop: (1, 266, 266, 144) after crop: (1, 265, 266, 144) spacing: [1. 1. 1.] \nbefore crop: (1, 266, 266, 144) after crop: (1, 265, 266, 144) spacing: [1. 1. 1.] \n\n\nbefore crop: (1, 266, 266, 144) after crop: (1, 265, 266, 144) spacing: [1. 1. 1.] \n\nbefore crop: (1, 266, 266, 144) after crop: (1, 265, 266, 144) spacing: [1. 1. 1.] \nbefore crop: (1, 266, 266, 144) after crop: (1, 265, 266, 144) spacing: [1. 1. 1.] \n\n\nbefore crop: (1, 266, 266, 144) after crop: (1, 265, 266, 144) spacing: [1. 1. 1.] \n\nbefore crop: (1, 266, 266, 144) after crop: (1, 265, 266, 144) spacing: [1. 1. 1.] \n\nbefore crop: (1, 360, 310, 144) after crop: (1, 359, 310, 144) spacing: [1. 1. 1.] \n\ncase36_day6\ncase36_day8\nbefore crop: (1, 266, 266, 144) after crop: (1, 265, 266, 144) spacing: [1. 1. 1.] \n\nbefore crop: (1, 266, 266, 144) after crop: (1, 265, 266, 144) spacing: [1. 1. 1.] \n\n\n\n\n Task522_UWMGITImageSegmentation\nnumber of threads:  (8, 8) \n\nAre we using the nonzero mask for normalization? OrderedDict([(0, False)])\nthe median shape of the dataset is  [265. 266. 144.]\nthe max shape in the dataset is  [359. 310. 144.]\nthe min shape in the dataset is  [265. 266. 144.]\nwe don't want feature maps smaller than  4  in the bottleneck\nthe transposed median shape of the dataset is  [265. 266. 144.]\ngenerating configuration for 3d_fullres\ngenerating configuration for 3d_lowres\n{0: {'batch_size': 2, 'num_pool_per_axis': [5, 5, 4], 'patch_size': array([160, 160,  96]), 'median_patient_size_in_voxels': array([265, 266, 144]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 1]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}}\ntranspose forward [0, 1, 2]\ntranspose backward [0, 1, 2]\nInitializing to run preprocessing\nnpz folder: /kaggle/working/input/nnUNet_raw_data_base/nnUNet_cropped_data/Task522_UWMGITImageSegmentation\noutput_folder: /kaggle/working/input/nnUNet_preprocessed/Task522_UWMGITImageSegmentation\nno resampling necessary\nno resampling necessary\nbefore: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 265, 266, 144)} \nafter:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 265, 266, 144)} \n\nno resampling necessary\nno resampling necessary\nbefore: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 265, 266, 144)} \nafter:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 265, 266, 144)} \n\nno resampling necessary\nno resampling necessary\nbefore: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 265, 266, 144)} \nafter:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 265, 266, 144)} \n\nno resampling necessary\nno resampling necessary\nbefore: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 265, 266, 144)} \nafter:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 265, 266, 144)} \n\nno resampling necessary\nno resampling necessary\nno resampling necessary\nbefore: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 265, 266, 144)} \nafter:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 265, 266, 144)} \n\nno resampling necessary\nbefore: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 265, 266, 144)} \nafter:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 265, 266, 144)} \n\nno resampling necessary\nno resampling necessary\nbefore: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 265, 266, 144)} \nafter:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 265, 266, 144)} \n\n1 10000\n2 10000\n1 10000\n1 10000\n3 10000\nsaving:  /kaggle/working/input/nnUNet_preprocessed/Task522_UWMGITImageSegmentation/nnUNetData_plans_v2.1_stage0/case135_day17.npz\n1 10000\n1 10000\n2 10000\n2 10000\nno resampling necessary\nno resampling necessary\nbefore: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 359, 310, 144)} \nafter:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 359, 310, 144)} \n\n1 10000\n1 10000\n2 10000\n3 10000\nsaving:  /kaggle/working/input/nnUNet_preprocessed/Task522_UWMGITImageSegmentation/nnUNetData_plans_v2.1_stage0/case22_day0.npz\n3 10000\nsaving:  /kaggle/working/input/nnUNet_preprocessed/Task522_UWMGITImageSegmentation/nnUNetData_plans_v2.1_stage0/case36_day10.npz\n2 10000\n2 10000\n3 10000\nsaving:  /kaggle/working/input/nnUNet_preprocessed/Task522_UWMGITImageSegmentation/nnUNetData_plans_v2.1_stage0/case20_day22.npz\n2 10000\n3 10000\nsaving:  /kaggle/working/input/nnUNet_preprocessed/Task522_UWMGITImageSegmentation/nnUNetData_plans_v2.1_stage0/case36_day16.npz\n3 10000\nsaving:  /kaggle/working/input/nnUNet_preprocessed/Task522_UWMGITImageSegmentation/nnUNetData_plans_v2.1_stage0/case135_day0.npz\n3 10000\nsaving:  /kaggle/working/input/nnUNet_preprocessed/Task522_UWMGITImageSegmentation/nnUNetData_plans_v2.1_stage0/case36_day14.npz\n1 10000\n2 10000\n3 10000\nsaving:  /kaggle/working/input/nnUNet_preprocessed/Task522_UWMGITImageSegmentation/nnUNetData_plans_v2.1_stage0/case36_day0.npz\nno resampling necessary\nno resampling necessary\nbefore: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 265, 266, 144)} \nafter:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 265, 266, 144)} \n\nno resampling necessary\nno resampling necessary\nbefore: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 265, 266, 144)} \nafter:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 265, 266, 144)} \n\n1 10000\n2 10000\n3 10000\nsaving:  /kaggle/working/input/nnUNet_preprocessed/Task522_UWMGITImageSegmentation/nnUNetData_plans_v2.1_stage0/case36_day8.npz\n1 10000\n2 10000\n3 10000\nsaving:  /kaggle/working/input/nnUNet_preprocessed/Task522_UWMGITImageSegmentation/nnUNetData_plans_v2.1_stage0/case36_day6.npz\nAre we using the nonzero mask for normalization? OrderedDict([(0, False)])\nthe median shape of the dataset is  [265. 266. 144.]\nthe max shape in the dataset is  [359. 310. 144.]\nthe min shape in the dataset is  [265. 266. 144.]\nwe don't want feature maps smaller than  4  in the bottleneck\nthe transposed median shape of the dataset is  [265. 266. 144.]\n[{'batch_size': 64, 'num_pool_per_axis': [6, 5], 'patch_size': array([320, 160]), 'median_patient_size_in_voxels': array([265, 266, 144]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 1]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}]\nInitializing to run preprocessing\nnpz folder: /kaggle/working/input/nnUNet_raw_data_base/nnUNet_cropped_data/Task522_UWMGITImageSegmentation\noutput_folder: /kaggle/working/input/nnUNet_preprocessed/Task522_UWMGITImageSegmentation\nno resampling necessary\nno resampling necessary\nbefore: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 265, 266, 144)} \nafter:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 265, 266, 144)} \n\nnormalization...\nno resampling necessary\nno resampling necessary\nbefore: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 265, 266, 144)} \nafter:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 265, 266, 144)} \n\nno resampling necessary\nno resampling necessary\nbefore: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 265, 266, 144)} \nafter:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 265, 266, 144)} \n\nno resampling necessary\nno resampling necessary\nbefore: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 265, 266, 144)} \nafter:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 265, 266, 144)} \n\nno resampling necessary\nno resampling necessary\nbefore: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 265, 266, 144)} \nafter:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 265, 266, 144)} \n\nnormalization...\nnormalization...\nnormalization...\nnormalization...\nno resampling necessary\nno resampling necessary\nbefore: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 265, 266, 144)} \nafter: no resampling necessary\nno resampling necessary\n {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 265, 266, 144)} \n\nbefore: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 265, 266, 144)} \nafter:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 265, 266, 144)} \n\nnormalization done\nnormalization...\nnormalization...\nnormalization done\nnormalization done\nnormalization done\nnormalization done\nnormalization done\nnormalization done\n1 10000\n1 10000\n1 10000\nno resampling necessary\nno resampling necessary\nbefore: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 359, 310, 144)} \nafter:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 359, 310, 144)} \n\n1 10000\n1 10000\n1 10000\n2 10000\nnormalization...\n1 10000\n2 10000\n2 10000\n2 10000\n3 10000\nsaving:  /kaggle/working/input/nnUNet_preprocessed/Task522_UWMGITImageSegmentation/nnUNetData_plans_v2.1_2D_stage0/case135_day0.npz\n2 10000\n2 10000\n3 10000\n2 10000\nsaving:  /kaggle/working/input/nnUNet_preprocessed/Task522_UWMGITImageSegmentation/nnUNetData_plans_v2.1_2D_stage0/case22_day0.npz\n3 10000\nsaving:  /kaggle/working/input/nnUNet_preprocessed/Task522_UWMGITImageSegmentation/nnUNetData_plans_v2.1_2D_stage0/case135_day17.npz\n3 10000\nsaving:  /kaggle/working/input/nnUNet_preprocessed/Task522_UWMGITImageSegmentation/nnUNetData_plans_v2.1_2D_stage0/case36_day10.npz\nnormalization done\n3 10000\n3 10000\nsaving:  /kaggle/working/input/nnUNet_preprocessed/Task522_UWMGITImageSegmentation/nnUNetData_plans_v2.1_2D_stage0/case20_day22.npz\n3 10000\nsaving:  /kaggle/working/input/nnUNet_preprocessed/Task522_UWMGITImageSegmentation/nnUNetData_plans_v2.1_2D_stage0/case36_day16.npz\nsaving:  /kaggle/working/input/nnUNet_preprocessed/Task522_UWMGITImageSegmentation/nnUNetData_plans_v2.1_2D_stage0/case36_day14.npz\n1 10000\n2 10000\n3 10000\nsaving:  /kaggle/working/input/nnUNet_preprocessed/Task522_UWMGITImageSegmentation/nnUNetData_plans_v2.1_2D_stage0/case36_day0.npz\nno resampling necessary\nno resampling necessary\nbefore: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 265, 266, 144)} \nafter:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 265, 266, 144)} \n\nnormalization...\nnormalization done\nno resampling necessary\nno resampling necessary\nbefore: {'spacing': array([1., 1., 1.]), 'spacing_transposed': array([1., 1., 1.]), 'data.shape (data is transposed)': (1, 265, 266, 144)} \nafter:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 265, 266, 144)} \n\nnormalization...\nnormalization done\n1 10000\n2 10000\n1 10000\n3 10000\nsaving:  /kaggle/working/input/nnUNet_preprocessed/Task522_UWMGITImageSegmentation/nnUNetData_plans_v2.1_2D_stage0/case36_day6.npz\n2 10000\n3 10000\nsaving:  /kaggle/working/input/nnUNet_preprocessed/Task522_UWMGITImageSegmentation/nnUNetData_plans_v2.1_2D_stage0/case36_day8.npz\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **nnUNet Training**","metadata":{}},{"cell_type":"code","source":" !nnUNet_train 3d_fullres nnUNetTrainerV2 522 0 --npz","metadata":{"execution":{"iopub.status.busy":"2024-05-15T21:50:08.470467Z","iopub.execute_input":"2024-05-15T21:50:08.471464Z","iopub.status.idle":"2024-05-15T21:56:17.286206Z","shell.execute_reply.started":"2024-05-15T21:50:08.471410Z","shell.execute_reply":"2024-05-15T21:56:17.284892Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"\n\nPlease cite the following paper when using nnUNet:\n\nIsensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n\n\nIf you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n\n###############################################\nI am running the following nnUNet: 3d_fullres\nMy trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>\nFor that I will be using the following configuration:\nnum_classes:  3\nmodalities:  {0: 'CT'}\nuse_mask_for_norm OrderedDict([(0, False)])\nkeep_only_largest_region None\nmin_region_size_per_class None\nmin_size_per_class None\nnormalization_schemes OrderedDict([(0, 'CT')])\nstages...\n\nstage:  0\n{'batch_size': 2, 'num_pool_per_axis': [5, 5, 4], 'patch_size': array([160, 160,  96]), 'median_patient_size_in_voxels': array([265, 266, 144]), 'current_spacing': array([1., 1., 1.]), 'original_spacing': array([1., 1., 1.]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 1]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}\n\nI am using stage 0 from these plans\nI am using sample dice + CE loss\n\nI am using data from this folder:  /kaggle/working/input/nnUNet_preprocessed/Task522_UWMGITImageSegmentation/nnUNetData_plans_v2.1\n###############################################\nloading dataset\nloading all case properties\n2024-05-15 21:50:12.141589: Creating new 5-fold cross-validation split...\n2024-05-15 21:50:12.142767: Desired fold for training: 0\n2024-05-15 21:50:12.142877: This split has 8 training and 2 validation cases.\nunpacking dataset\ndone\n2024-05-15 21:50:17.331726: lr: 0.01\nusing pin_memory on device 0\nusing pin_memory on device 0\n2024-05-15 21:50:46.910441: Unable to plot network architecture:\n2024-05-15 21:50:46.910749: No module named 'hiddenlayer'\n2024-05-15 21:50:46.910869: \nprinting the network instead:\n\n2024-05-15 21:50:46.910970: Generic_UNet(\n  (conv_blocks_localization): ModuleList(\n    (0): Sequential(\n      (0): StackedConvLayers(\n        (blocks): Sequential(\n          (0): ConvDropoutNormNonlin(\n            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n          )\n        )\n      )\n      (1): StackedConvLayers(\n        (blocks): Sequential(\n          (0): ConvDropoutNormNonlin(\n            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n          )\n        )\n      )\n    )\n    (1): Sequential(\n      (0): StackedConvLayers(\n        (blocks): Sequential(\n          (0): ConvDropoutNormNonlin(\n            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n          )\n        )\n      )\n      (1): StackedConvLayers(\n        (blocks): Sequential(\n          (0): ConvDropoutNormNonlin(\n            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n          )\n        )\n      )\n    )\n    (2): Sequential(\n      (0): StackedConvLayers(\n        (blocks): Sequential(\n          (0): ConvDropoutNormNonlin(\n            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n          )\n        )\n      )\n      (1): StackedConvLayers(\n        (blocks): Sequential(\n          (0): ConvDropoutNormNonlin(\n            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n          )\n        )\n      )\n    )\n    (3): Sequential(\n      (0): StackedConvLayers(\n        (blocks): Sequential(\n          (0): ConvDropoutNormNonlin(\n            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n          )\n        )\n      )\n      (1): StackedConvLayers(\n        (blocks): Sequential(\n          (0): ConvDropoutNormNonlin(\n            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n          )\n        )\n      )\n    )\n    (4): Sequential(\n      (0): StackedConvLayers(\n        (blocks): Sequential(\n          (0): ConvDropoutNormNonlin(\n            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n          )\n        )\n      )\n      (1): StackedConvLayers(\n        (blocks): Sequential(\n          (0): ConvDropoutNormNonlin(\n            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n          )\n        )\n      )\n    )\n  )\n  (conv_blocks_context): ModuleList(\n    (0): StackedConvLayers(\n      (blocks): Sequential(\n        (0): ConvDropoutNormNonlin(\n          (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n        )\n        (1): ConvDropoutNormNonlin(\n          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n        )\n      )\n    )\n    (1): StackedConvLayers(\n      (blocks): Sequential(\n        (0): ConvDropoutNormNonlin(\n          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n        )\n        (1): ConvDropoutNormNonlin(\n          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n        )\n      )\n    )\n    (2): StackedConvLayers(\n      (blocks): Sequential(\n        (0): ConvDropoutNormNonlin(\n          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n        )\n        (1): ConvDropoutNormNonlin(\n          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n        )\n      )\n    )\n    (3): StackedConvLayers(\n      (blocks): Sequential(\n        (0): ConvDropoutNormNonlin(\n          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n        )\n        (1): ConvDropoutNormNonlin(\n          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n        )\n      )\n    )\n    (4): StackedConvLayers(\n      (blocks): Sequential(\n        (0): ConvDropoutNormNonlin(\n          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n        )\n        (1): ConvDropoutNormNonlin(\n          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n        )\n      )\n    )\n    (5): Sequential(\n      (0): StackedConvLayers(\n        (blocks): Sequential(\n          (0): ConvDropoutNormNonlin(\n            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 1), padding=(1, 1, 1))\n            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n          )\n        )\n      )\n      (1): StackedConvLayers(\n        (blocks): Sequential(\n          (0): ConvDropoutNormNonlin(\n            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n          )\n        )\n      )\n    )\n  )\n  (td): ModuleList()\n  (tu): ModuleList(\n    (0): ConvTranspose3d(320, 320, kernel_size=(2, 2, 1), stride=(2, 2, 1), bias=False)\n    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n  )\n  (seg_outputs): ModuleList(\n    (0): Conv3d(320, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n    (1): Conv3d(256, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n    (2): Conv3d(128, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n    (3): Conv3d(64, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n    (4): Conv3d(32, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n  )\n)\n2024-05-15 21:50:46.915818: \n\n2024-05-15 21:50:46.916108: \nepoch:  0\n^C\n","output_type":"stream"}]}]}